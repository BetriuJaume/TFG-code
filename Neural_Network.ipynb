{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGwJYfAKJfL6ddvtXtuM8s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BetriuJaume/TFG-code/blob/main/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for the deep learning model:"
      ],
      "metadata": {
        "id": "RTujJSA8siAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyreadstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zcHtu4VqJ_O",
        "outputId": "513c4038-f7bc-4061-b83c-6b0b5bd7afdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyreadstat\n",
            "  Downloading pyreadstat-1.1.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyreadstat) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadstat) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadstat) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyreadstat) (1.15.0)\n",
            "Installing collected packages: pyreadstat\n",
            "Successfully installed pyreadstat-1.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlmUex8DpoLh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data_utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility:\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP9IVG2Vandn",
        "outputId": "27bf7833-9268-426c-a899-1b2e04f16f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f34f2fb57d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dades_orig=pd.read_spss('EarlyLifeCovidPACIENTES V6 ID.sav')\n",
        "dades_extra=pd.read_spss('extra_data.sav')\n",
        "\n",
        "dades_extra['Talla_mt'] = dades_extra['Talla']/100\n",
        "dades_extra=dades_extra.rename(columns = {'Tabaco_Sino':'Tabaco_SIno'})\n",
        "dades_extra=dades_extra.drop(list(set(dades_extra.columns)-set(dades_orig)),axis=1)\n",
        "dades_extra['IUGR_missing']= [1.]*len(dades_extra)\n",
        "\n",
        "for colu in dades_extra.columns[12:-2]:\n",
        "    dades_extra[colu]=['si' if x==1 else 'no' for x in dades_extra[colu]]\n",
        "\n",
        "dades=pd.concat([dades_orig, dades_extra], ignore_index=True)\n",
        "\n",
        "def canvi_tab(elem):\n",
        "  if((elem=='si (pasado o actual)') | \n",
        "     (elem=='si (actual o pasado)')):\n",
        "    return 'yes'\n",
        "  if(elem=='nunca'):\n",
        "    return 'no'\n",
        "def canvi(elem):\n",
        "  if(elem=='si'):\n",
        "    return 'yes'\n",
        "  if(elem=='no'):\n",
        "    return 'no'\n",
        "def canvi_UCI(elem):\n",
        "  if(elem==1):\n",
        "    return 'Yes'\n",
        "  if(elem==0):\n",
        "    return 'No'\n",
        "def canvi_sex(elem):\n",
        "  if(elem=='mujer'):\n",
        "    return 'woman'\n",
        "  if(elem=='hombre'):\n",
        "    return 'man'\n",
        "\n",
        "dades['Tabaco_SIno']=dades['Tabaco_SIno'].apply(canvi_tab)\n",
        "dades['UCI']=dades['UCI'].apply(canvi_UCI)\n",
        "for columna in dades.columns[14:]:\n",
        "  dades[columna]=dades[columna].apply(canvi)\n",
        "dades['Gender']=dades['Gender'].apply(canvi_sex)\n",
        "dades['IUGR_calc']=dades['IUGR_calc'].apply(canvi_UCI)\n",
        "\n",
        "dades_no_translate = dades.copy()\n",
        "\n",
        "dades.columns=pd.Index(['ID', 'UCI', 'IUGR_missing', 'Age', 'Gender', 'Size', 'Weight',\n",
        "       'Size_mt', 'IMC', 'BW', 'BW_2500', 'percentil_birth', 'IUGR_calc',\n",
        "       'Tobacco_yes_no', 'Hipertension', 'Heart_diseases', 'DM', 'Dyslipidemia',\n",
        "       'Obesity', 'Kidney_disease', 'Autoimmune', 'Cancer', 'Thyroid', 'Infectious',\n",
        "       'Psychiatric'])\n",
        "\n",
        "dades['Age']=dades['Age'].fillna(dades['Age'].mean())\n",
        "dades['Size']=dades['Size'].fillna(dades['Size'].mean())\n",
        "dades['Weight']=dades['Weight'].fillna(dades['Weight'].mean())\n",
        "dades['Size_mt']=dades['Size']/100\n",
        "dades['IMC']=dades['IMC'].fillna(dades['IMC'].mean())\n",
        "dades['percentil_birth']=dades['percentil_birth'].fillna(dades['percentil_birth'].mean())\n",
        "dades['IUGR_calc']=dades['IUGR_calc'].fillna(dades['IUGR_calc'].mode().iloc[0])"
      ],
      "metadata": {
        "id": "TsGzYk68qGBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dades_train = dades.sample(frac=0.8, random_state=25).drop('ID',axis=1)\n",
        "dades_test = dades.drop(dades_train.index).drop('ID',axis=1)"
      ],
      "metadata": {
        "id": "7TZfQunZqJRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design, training and hiperparameter adjusting of the Neural Network"
      ],
      "metadata": {
        "id": "b0ZTSHiftI0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing of the data:\n",
        "\n",
        "Codification of the data into Torch tensors:"
      ],
      "metadata": {
        "id": "UW3cdd8ctev-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions that will help for the codification:\n",
        "\n",
        "def codGender(elem):\n",
        "  if elem=='man':\n",
        "    return 1.\n",
        "  else:\n",
        "    return 0.\n",
        "def codUCI(elem):\n",
        "  if elem=='Yes':\n",
        "    return 1.\n",
        "  else:\n",
        "    return 0.\n",
        "def codBW(elem):\n",
        "  if elem=='BW normal':\n",
        "    return 0.\n",
        "  else:\n",
        "    return 1.\n",
        "def cod(elem):\n",
        "  if elem=='yes':\n",
        "    return 1.\n",
        "  else:\n",
        "    return 0."
      ],
      "metadata": {
        "id": "1DjbyswVtH0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dades_cod_train=dades_train.drop(['IUGR_missing', 'Size', 'BW'],axis=1).copy()\n",
        "dades_cod_test=dades_test.drop(['IUGR_missing', 'Size', 'BW'],axis=1).copy()\n",
        "\n",
        "for df in [dades_cod_train,dades_cod_test]:\n",
        "  df['UCI']=df['UCI'].apply(codUCI)\n",
        "  df['Gender']=df['Gender'].apply(codGender)\n",
        "  df['BW_2500']=df['BW_2500'].apply(codBW)\n",
        "  df['IUGR_calc']=df['IUGR_calc'].apply(codUCI)\n",
        "  for element in df.columns[9:]:\n",
        "    df[element]=df[element].apply(cod)\n",
        "\n",
        "target_train=torch.tensor(dades_cod_train['UCI'].values)\n",
        "features_train=torch.tensor(dades_cod_train.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_train=TensorDataset(features_train,target_train)\n",
        "\n",
        "target_test=torch.tensor(dades_cod_test['UCI'].values)\n",
        "features_test=torch.tensor(dades_cod_test.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_test=TensorDataset(features_test,target_test)"
      ],
      "metadata": {
        "id": "4HfoKAW1tu23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_torch = Dades_Tensor_train\n",
        "test_torch = Dades_Tensor_test\n",
        "\n",
        "train_torch1=DataLoader(train_torch,batch_size=100,shuffle=True)\n",
        "test_torch1=DataLoader(test_torch,batch_size=len(features_test),shuffle=True)"
      ],
      "metadata": {
        "id": "wEfgPGYytxcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if CPU acceleration is activated:"
      ],
      "metadata": {
        "id": "QsxW1dOBPZpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print('Cuda available')\n",
        "else:\n",
        "  print('Cuda not available')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UIaDnw3O8uq",
        "outputId": "f79be8e1-c60d-4e2c-eaf9-64834e7103bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Design and training:\n",
        "We begin building the class for the network:"
      ],
      "metadata": {
        "id": "LgaLqvVLt4D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.input_layer=nn.Linear(features_train.size()[1],14) #weights\n",
        "    #self.hidden1=nn.Linear(14,14)\n",
        "    #self.hidden2=nn.Linear(7,7)\n",
        "    #self.hidden3=nn.Linear(7,10)\n",
        "    #self.hidden4=nn.Linear(10,7)\n",
        "    self.output=nn.Linear(14,2)\n",
        "  \n",
        "  def forward(self, data): #activation functions, we will use the ReLu function\n",
        "    data=F.relu(self.input_layer(data))\n",
        "    #data=F.relu(self.hidden1(data))\n",
        "    #data=F.relu(self.hidden2(data))\n",
        "    #data=F.relu(self.hidden3(data))\n",
        "    #data=F.relu(self.hidden4(data))\n",
        "    data=self.output(data)\n",
        "    return F.softmax(data, dim=1)"
      ],
      "metadata": {
        "id": "1sP4C_4WtxfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test functions:"
      ],
      "metadata": {
        "id": "Gagcw9khOAHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, data_loader, loss_function, optimiser, device):\n",
        "  for inputs, targets in data_loader:\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # We have to calculate the loss\n",
        "    predictions = model(inputs.float())\n",
        "    loss = loss_function(predictions, targets.long())\n",
        "\n",
        "    # Update the weights\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "  print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "def train(model, data_loader, loss_function, optimiser, device, epochs):\n",
        "  for i in range(epochs):\n",
        "    print(f\"Epoch {i}\")\n",
        "    train_one_epoch(model, data_loader, loss_function, optimiser, device)\n",
        "    print('_______________________')\n",
        "   \n",
        "  print('End of training')\n",
        "\n",
        "\n",
        "\n",
        "def predict(model, input, target):\n",
        "  model.eval() #we activate eval so the network knows we are testing\n",
        "  with torch.no_grad():\n",
        "    predictions = model(input) #.argmax(dim=1)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "1g4rN7eMN5KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network().to(\"cuda\")\n",
        "\n",
        "#training the network:\n",
        "train(model=network, \n",
        "      data_loader=train_torch1, \n",
        "      loss_function=F.nll_loss, \n",
        "      device=\"cuda\", \n",
        "      optimiser=optim.Adam(network.parameters(),lr=0.0001),\n",
        "      epochs=10)\n",
        "\n",
        "#We store the model in case we want to use it in another script:\n",
        "torch.save(network.state_dict(), \"NN_model_for_COVID-19_patients.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMkaxpxTrpDs",
        "outputId": "06285676-63ef-4295-e7cb-4bb666163898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Loss: -0.9230532050132751\n",
            "_______________________\n",
            "Epoch 1\n",
            "Loss: -0.9615135192871094\n",
            "_______________________\n",
            "Epoch 2\n",
            "Loss: -0.9999818205833435\n",
            "_______________________\n",
            "Epoch 3\n",
            "Loss: -0.9999852776527405\n",
            "_______________________\n",
            "Epoch 4\n",
            "Loss: -0.9999797344207764\n",
            "_______________________\n",
            "Epoch 5\n",
            "Loss: -0.9615230560302734\n",
            "_______________________\n",
            "Epoch 6\n",
            "Loss: -0.9615351557731628\n",
            "_______________________\n",
            "Epoch 7\n",
            "Loss: -0.9999963045120239\n",
            "_______________________\n",
            "Epoch 8\n",
            "Loss: -0.9999987483024597\n",
            "_______________________\n",
            "Epoch 9\n",
            "Loss: -0.8846145868301392\n",
            "_______________________\n",
            "End of training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model has a very bad performance even in the train data. This is shown by the values of the log likelihood cost function. This might we caused because the network has very few examples of patients with a 'Yes' in UCI."
      ],
      "metadata": {
        "id": "mI-yhB7XGEJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results. First we will load the model from \"NN_model_for_COVID-19_patients.pth\"\n",
        "network_for_test = Network()\n",
        "state_dict = torch.load(\"NN_model_for_COVID-19_patients.pth\")\n",
        "network_for_test.load_state_dict(state_dict)\n",
        "\n",
        "for input, target in test_torch1:\n",
        "  predictions = predict(network_for_test, input.float(), target)\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fm7yEeOa-nw",
        "outputId": "59c886a9-275c-4476-fbe6-31c2293b1196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e+00, 5.5092e-18],\n",
            "        [1.0000e+00, 3.8686e-13],\n",
            "        [1.0000e+00, 1.2485e-12],\n",
            "        [1.0000e+00, 2.7915e-11],\n",
            "        [1.0000e+00, 3.5713e-11],\n",
            "        [1.0000e+00, 2.5624e-14],\n",
            "        [1.0000e+00, 7.0726e-22],\n",
            "        [1.0000e+00, 2.5692e-23],\n",
            "        [1.0000e+00, 9.2238e-18],\n",
            "        [1.0000e+00, 1.0203e-17],\n",
            "        [1.0000e+00, 1.4708e-13],\n",
            "        [1.0000e+00, 3.7881e-15],\n",
            "        [1.0000e+00, 5.1226e-14],\n",
            "        [1.0000e+00, 6.6728e-14],\n",
            "        [1.0000e+00, 1.4732e-15],\n",
            "        [1.0000e+00, 6.8183e-20],\n",
            "        [1.0000e+00, 8.9012e-12],\n",
            "        [1.0000e+00, 1.7975e-20],\n",
            "        [1.0000e+00, 2.2305e-16],\n",
            "        [1.0000e+00, 2.9087e-19],\n",
            "        [1.0000e+00, 1.2714e-19],\n",
            "        [1.0000e+00, 4.2847e-17],\n",
            "        [1.0000e+00, 3.1279e-13],\n",
            "        [1.0000e+00, 7.2486e-18],\n",
            "        [1.0000e+00, 4.3481e-11],\n",
            "        [1.0000e+00, 1.1529e-13],\n",
            "        [1.0000e+00, 3.8934e-18],\n",
            "        [1.0000e+00, 2.7604e-19],\n",
            "        [1.0000e+00, 2.6488e-15],\n",
            "        [1.0000e+00, 3.6510e-13],\n",
            "        [1.0000e+00, 4.1133e-21],\n",
            "        [1.0000e+00, 6.5969e-14],\n",
            "        [1.0000e+00, 9.7006e-20],\n",
            "        [1.0000e+00, 1.2284e-16],\n",
            "        [1.0000e+00, 9.5414e-23],\n",
            "        [1.0000e+00, 3.2176e-19],\n",
            "        [1.0000e+00, 2.0400e-18],\n",
            "        [1.0000e+00, 3.0516e-13],\n",
            "        [1.0000e+00, 1.0189e-12],\n",
            "        [1.0000e+00, 1.1277e-16],\n",
            "        [1.0000e+00, 1.8627e-18],\n",
            "        [1.0000e+00, 3.2059e-18],\n",
            "        [1.0000e+00, 1.1515e-25],\n",
            "        [1.0000e+00, 1.0679e-11],\n",
            "        [1.0000e+00, 2.7650e-16],\n",
            "        [1.0000e+00, 4.6255e-15],\n",
            "        [1.0000e+00, 1.4307e-18],\n",
            "        [1.0000e+00, 2.1770e-11],\n",
            "        [1.0000e+00, 4.7334e-16],\n",
            "        [1.0000e+00, 2.1939e-15],\n",
            "        [1.0000e+00, 2.7413e-14],\n",
            "        [1.0000e+00, 2.7926e-18],\n",
            "        [1.0000e+00, 4.0982e-19],\n",
            "        [1.0000e+00, 1.2057e-13],\n",
            "        [1.0000e+00, 4.1971e-16],\n",
            "        [1.0000e+00, 7.4815e-15],\n",
            "        [1.0000e+00, 7.8984e-27],\n",
            "        [1.0000e+00, 5.8204e-19],\n",
            "        [1.0000e+00, 6.4715e-17],\n",
            "        [1.0000e+00, 1.3026e-14],\n",
            "        [1.0000e+00, 9.1442e-13],\n",
            "        [1.0000e+00, 5.6284e-17],\n",
            "        [1.0000e+00, 3.3789e-14],\n",
            "        [1.0000e+00, 3.0655e-16],\n",
            "        [1.0000e+00, 1.5084e-15],\n",
            "        [1.0000e+00, 1.7818e-16],\n",
            "        [1.0000e+00, 6.6745e-22],\n",
            "        [1.0000e+00, 3.2398e-21],\n",
            "        [1.0000e+00, 6.4210e-15],\n",
            "        [1.0000e+00, 7.2115e-20],\n",
            "        [1.0000e+00, 1.2743e-20],\n",
            "        [1.0000e+00, 1.3631e-24],\n",
            "        [1.0000e+00, 4.9716e-19],\n",
            "        [1.0000e+00, 1.5738e-14],\n",
            "        [1.0000e+00, 6.5638e-14],\n",
            "        [1.0000e+00, 1.2239e-21],\n",
            "        [1.0000e+00, 6.9561e-19],\n",
            "        [1.0000e+00, 1.0035e-18],\n",
            "        [1.0000e+00, 4.1368e-25],\n",
            "        [1.0000e+00, 3.0133e-20],\n",
            "        [1.0000e+00, 1.4728e-21],\n",
            "        [1.0000e+00, 7.3426e-16],\n",
            "        [1.0000e+00, 8.0710e-19],\n",
            "        [1.0000e+00, 3.1851e-18],\n",
            "        [1.0000e+00, 1.3515e-25],\n",
            "        [1.0000e+00, 5.8077e-17],\n",
            "        [1.0000e+00, 4.0486e-12],\n",
            "        [1.0000e+00, 4.0787e-19],\n",
            "        [1.0000e+00, 1.7956e-11],\n",
            "        [1.0000e+00, 2.9688e-19],\n",
            "        [1.0000e+00, 1.3466e-22],\n",
            "        [1.0000e+00, 4.5279e-17],\n",
            "        [1.0000e+00, 3.2411e-18],\n",
            "        [1.0000e+00, 1.5874e-14],\n",
            "        [1.0000e+00, 2.1201e-14],\n",
            "        [1.0000e+00, 1.1387e-16],\n",
            "        [1.0000e+00, 6.0326e-17],\n",
            "        [1.0000e+00, 2.0211e-17],\n",
            "        [1.0000e+00, 5.7196e-19],\n",
            "        [1.0000e+00, 3.4628e-13],\n",
            "        [1.0000e+00, 1.6404e-21],\n",
            "        [1.0000e+00, 4.9001e-21],\n",
            "        [1.0000e+00, 5.1981e-14],\n",
            "        [1.0000e+00, 3.4695e-19],\n",
            "        [1.0000e+00, 1.7939e-19],\n",
            "        [1.0000e+00, 2.7852e-12],\n",
            "        [1.0000e+00, 1.4219e-18],\n",
            "        [1.0000e+00, 3.0421e-14],\n",
            "        [1.0000e+00, 1.1062e-15],\n",
            "        [1.0000e+00, 2.3311e-13],\n",
            "        [1.0000e+00, 8.3607e-20],\n",
            "        [1.0000e+00, 8.3110e-15],\n",
            "        [1.0000e+00, 1.4352e-17],\n",
            "        [1.0000e+00, 2.5174e-21],\n",
            "        [1.0000e+00, 2.1225e-13],\n",
            "        [1.0000e+00, 1.6733e-14],\n",
            "        [1.0000e+00, 5.4454e-15],\n",
            "        [1.0000e+00, 1.7422e-14],\n",
            "        [1.0000e+00, 5.0552e-15],\n",
            "        [1.0000e+00, 1.8650e-19],\n",
            "        [1.0000e+00, 2.0220e-32],\n",
            "        [1.0000e+00, 1.1902e-11],\n",
            "        [1.0000e+00, 1.3339e-15],\n",
            "        [1.0000e+00, 1.5011e-15],\n",
            "        [1.0000e+00, 2.1343e-20],\n",
            "        [1.0000e+00, 4.2709e-14],\n",
            "        [1.0000e+00, 1.1459e-22],\n",
            "        [1.0000e+00, 7.4755e-18],\n",
            "        [1.0000e+00, 5.6713e-11],\n",
            "        [1.0000e+00, 1.6639e-17],\n",
            "        [1.0000e+00, 9.1763e-16],\n",
            "        [1.0000e+00, 1.7638e-27],\n",
            "        [1.0000e+00, 5.5432e-15],\n",
            "        [1.0000e+00, 1.5833e-20],\n",
            "        [1.0000e+00, 1.2524e-15],\n",
            "        [1.0000e+00, 6.6146e-13],\n",
            "        [1.0000e+00, 1.6683e-10],\n",
            "        [1.0000e+00, 1.4343e-14],\n",
            "        [1.0000e+00, 1.9970e-19],\n",
            "        [1.0000e+00, 1.4657e-23],\n",
            "        [1.0000e+00, 4.0962e-13],\n",
            "        [1.0000e+00, 1.2436e-12],\n",
            "        [1.0000e+00, 3.7350e-15],\n",
            "        [1.0000e+00, 2.3405e-11],\n",
            "        [1.0000e+00, 3.6279e-19],\n",
            "        [1.0000e+00, 1.7015e-11],\n",
            "        [1.0000e+00, 1.7802e-21],\n",
            "        [1.0000e+00, 7.5706e-17],\n",
            "        [1.0000e+00, 1.3429e-20],\n",
            "        [1.0000e+00, 5.8100e-12],\n",
            "        [1.0000e+00, 8.4454e-13],\n",
            "        [1.0000e+00, 2.4714e-14],\n",
            "        [1.0000e+00, 1.5429e-16],\n",
            "        [1.0000e+00, 1.0073e-14],\n",
            "        [1.0000e+00, 3.1891e-14],\n",
            "        [1.0000e+00, 2.0496e-19],\n",
            "        [1.0000e+00, 7.5424e-13],\n",
            "        [1.0000e+00, 6.1348e-13],\n",
            "        [1.0000e+00, 3.3729e-10],\n",
            "        [1.0000e+00, 1.7093e-18],\n",
            "        [1.0000e+00, 4.1619e-30],\n",
            "        [1.0000e+00, 1.4819e-12],\n",
            "        [1.0000e+00, 3.8594e-21],\n",
            "        [1.0000e+00, 4.1701e-15],\n",
            "        [1.0000e+00, 3.1647e-18],\n",
            "        [1.0000e+00, 9.4392e-21],\n",
            "        [1.0000e+00, 2.8741e-18],\n",
            "        [1.0000e+00, 1.4396e-14],\n",
            "        [1.0000e+00, 3.5327e-16],\n",
            "        [1.0000e+00, 4.7110e-17],\n",
            "        [1.0000e+00, 1.3942e-18],\n",
            "        [1.0000e+00, 2.4458e-15],\n",
            "        [1.0000e+00, 4.0787e-11],\n",
            "        [1.0000e+00, 1.4675e-17],\n",
            "        [1.0000e+00, 8.1281e-15],\n",
            "        [1.0000e+00, 7.9643e-30],\n",
            "        [1.0000e+00, 6.6596e-15],\n",
            "        [1.0000e+00, 1.3942e-14],\n",
            "        [1.0000e+00, 3.7688e-16],\n",
            "        [1.0000e+00, 1.4668e-17],\n",
            "        [1.0000e+00, 8.2501e-20],\n",
            "        [1.0000e+00, 7.4533e-16],\n",
            "        [1.0000e+00, 1.6079e-16],\n",
            "        [1.0000e+00, 1.9781e-14],\n",
            "        [1.0000e+00, 8.0112e-18],\n",
            "        [1.0000e+00, 5.0281e-17],\n",
            "        [1.0000e+00, 7.1772e-15],\n",
            "        [1.0000e+00, 1.0214e-24],\n",
            "        [1.0000e+00, 8.1820e-13],\n",
            "        [1.0000e+00, 1.9322e-16],\n",
            "        [1.0000e+00, 3.3362e-17],\n",
            "        [1.0000e+00, 3.9995e-17],\n",
            "        [1.0000e+00, 7.3563e-14],\n",
            "        [1.0000e+00, 1.7622e-17],\n",
            "        [1.0000e+00, 3.4597e-16],\n",
            "        [1.0000e+00, 6.1679e-15],\n",
            "        [1.0000e+00, 8.6906e-22],\n",
            "        [1.0000e+00, 2.2760e-14],\n",
            "        [1.0000e+00, 1.4530e-12],\n",
            "        [1.0000e+00, 1.7971e-17],\n",
            "        [1.0000e+00, 7.5861e-14],\n",
            "        [1.0000e+00, 2.6983e-15],\n",
            "        [1.0000e+00, 5.5285e-19],\n",
            "        [1.0000e+00, 3.3974e-22],\n",
            "        [1.0000e+00, 3.7076e-13],\n",
            "        [1.0000e+00, 2.2997e-17],\n",
            "        [1.0000e+00, 5.7526e-14],\n",
            "        [1.0000e+00, 1.9805e-16],\n",
            "        [1.0000e+00, 3.5853e-12],\n",
            "        [1.0000e+00, 7.7954e-15],\n",
            "        [1.0000e+00, 9.3702e-15],\n",
            "        [1.0000e+00, 1.2942e-11],\n",
            "        [1.0000e+00, 1.1247e-15],\n",
            "        [1.0000e+00, 1.5109e-15],\n",
            "        [1.0000e+00, 5.2431e-15],\n",
            "        [1.0000e+00, 9.1210e-15],\n",
            "        [1.0000e+00, 4.1250e-17],\n",
            "        [1.0000e+00, 2.0777e-16],\n",
            "        [1.0000e+00, 1.1643e-18],\n",
            "        [1.0000e+00, 8.0742e-17],\n",
            "        [1.0000e+00, 6.6573e-13],\n",
            "        [1.0000e+00, 8.2946e-15],\n",
            "        [1.0000e+00, 6.0066e-19],\n",
            "        [1.0000e+00, 2.4399e-14],\n",
            "        [1.0000e+00, 7.7049e-12],\n",
            "        [1.0000e+00, 2.6997e-12],\n",
            "        [1.0000e+00, 5.5192e-18],\n",
            "        [1.0000e+00, 3.5202e-12],\n",
            "        [1.0000e+00, 7.8024e-14],\n",
            "        [1.0000e+00, 8.2069e-24],\n",
            "        [1.0000e+00, 5.4446e-17],\n",
            "        [1.0000e+00, 1.7536e-16],\n",
            "        [1.0000e+00, 9.5650e-21],\n",
            "        [1.0000e+00, 1.2527e-15],\n",
            "        [1.0000e+00, 5.7960e-12],\n",
            "        [1.0000e+00, 5.8597e-13],\n",
            "        [1.0000e+00, 1.1518e-12],\n",
            "        [1.0000e+00, 1.0247e-25],\n",
            "        [1.0000e+00, 1.4951e-17],\n",
            "        [1.0000e+00, 8.7347e-16],\n",
            "        [1.0000e+00, 7.4409e-16],\n",
            "        [1.0000e+00, 5.5702e-15],\n",
            "        [1.0000e+00, 7.6214e-21],\n",
            "        [1.0000e+00, 1.0270e-16],\n",
            "        [1.0000e+00, 2.7639e-20],\n",
            "        [1.0000e+00, 1.9570e-17],\n",
            "        [1.0000e+00, 3.7939e-14],\n",
            "        [1.0000e+00, 5.2434e-22],\n",
            "        [1.0000e+00, 1.4998e-17],\n",
            "        [1.0000e+00, 1.4908e-17],\n",
            "        [1.0000e+00, 7.5106e-12],\n",
            "        [1.0000e+00, 7.6606e-19],\n",
            "        [1.0000e+00, 5.2401e-16],\n",
            "        [1.0000e+00, 1.0687e-16],\n",
            "        [1.0000e+00, 7.8920e-18],\n",
            "        [1.0000e+00, 4.0904e-21],\n",
            "        [1.0000e+00, 4.4956e-17],\n",
            "        [1.0000e+00, 1.4457e-18],\n",
            "        [1.0000e+00, 4.5176e-18],\n",
            "        [1.0000e+00, 3.5474e-16],\n",
            "        [1.0000e+00, 4.8299e-12],\n",
            "        [1.0000e+00, 1.7985e-34],\n",
            "        [1.0000e+00, 4.5866e-14],\n",
            "        [1.0000e+00, 2.2391e-14],\n",
            "        [1.0000e+00, 2.2873e-13],\n",
            "        [1.0000e+00, 2.3710e-18],\n",
            "        [1.0000e+00, 2.3095e-19],\n",
            "        [1.0000e+00, 1.2948e-19],\n",
            "        [1.0000e+00, 2.5496e-21],\n",
            "        [1.0000e+00, 6.3122e-16],\n",
            "        [1.0000e+00, 5.7023e-14],\n",
            "        [1.0000e+00, 2.4863e-16],\n",
            "        [1.0000e+00, 3.1184e-15],\n",
            "        [1.0000e+00, 1.9673e-16],\n",
            "        [1.0000e+00, 9.5074e-19],\n",
            "        [1.0000e+00, 5.9739e-20],\n",
            "        [1.0000e+00, 6.9545e-18],\n",
            "        [1.0000e+00, 7.4725e-14],\n",
            "        [1.0000e+00, 5.3206e-16],\n",
            "        [1.0000e+00, 6.4777e-24],\n",
            "        [1.0000e+00, 8.5835e-16],\n",
            "        [1.0000e+00, 6.4038e-16],\n",
            "        [1.0000e+00, 2.9343e-19],\n",
            "        [1.0000e+00, 2.8351e-18],\n",
            "        [1.0000e+00, 3.8452e-12],\n",
            "        [1.0000e+00, 4.8781e-19],\n",
            "        [1.0000e+00, 7.8210e-12],\n",
            "        [1.0000e+00, 3.2652e-18],\n",
            "        [1.0000e+00, 8.7198e-14],\n",
            "        [1.0000e+00, 3.3653e-17],\n",
            "        [1.0000e+00, 2.6231e-20],\n",
            "        [1.0000e+00, 3.9220e-13],\n",
            "        [1.0000e+00, 2.8128e-17],\n",
            "        [1.0000e+00, 1.3725e-18],\n",
            "        [1.0000e+00, 1.4035e-14],\n",
            "        [1.0000e+00, 1.3603e-13],\n",
            "        [1.0000e+00, 3.7338e-13],\n",
            "        [1.0000e+00, 9.5904e-13],\n",
            "        [1.0000e+00, 4.4906e-19],\n",
            "        [1.0000e+00, 3.6473e-14],\n",
            "        [1.0000e+00, 4.1362e-12],\n",
            "        [1.0000e+00, 1.3266e-16],\n",
            "        [1.0000e+00, 1.0914e-17],\n",
            "        [1.0000e+00, 4.9320e-20],\n",
            "        [1.0000e+00, 1.2347e-17],\n",
            "        [1.0000e+00, 1.6879e-16],\n",
            "        [1.0000e+00, 1.5540e-12],\n",
            "        [1.0000e+00, 1.5113e-17],\n",
            "        [1.0000e+00, 5.8831e-13],\n",
            "        [1.0000e+00, 3.6102e-19],\n",
            "        [1.0000e+00, 3.3270e-16],\n",
            "        [1.0000e+00, 8.4759e-14],\n",
            "        [1.0000e+00, 3.5481e-22],\n",
            "        [1.0000e+00, 7.3156e-16],\n",
            "        [1.0000e+00, 4.2011e-17],\n",
            "        [1.0000e+00, 2.4182e-17],\n",
            "        [1.0000e+00, 5.8053e-16],\n",
            "        [1.0000e+00, 1.4342e-11],\n",
            "        [1.0000e+00, 4.3682e-16],\n",
            "        [1.0000e+00, 1.7013e-19],\n",
            "        [1.0000e+00, 3.4766e-13],\n",
            "        [1.0000e+00, 9.4081e-19],\n",
            "        [1.0000e+00, 5.4884e-12],\n",
            "        [1.0000e+00, 5.0796e-16],\n",
            "        [1.0000e+00, 2.8467e-17],\n",
            "        [1.0000e+00, 3.2480e-13],\n",
            "        [1.0000e+00, 1.4402e-12],\n",
            "        [1.0000e+00, 3.6211e-16],\n",
            "        [1.0000e+00, 2.4205e-18],\n",
            "        [1.0000e+00, 4.9149e-16],\n",
            "        [1.0000e+00, 4.2700e-17],\n",
            "        [1.0000e+00, 6.4357e-15],\n",
            "        [1.0000e+00, 6.7304e-14],\n",
            "        [1.0000e+00, 1.7045e-14],\n",
            "        [1.0000e+00, 3.5654e-17],\n",
            "        [1.0000e+00, 2.1054e-13],\n",
            "        [1.0000e+00, 1.0857e-14],\n",
            "        [1.0000e+00, 5.7659e-14],\n",
            "        [1.0000e+00, 6.7468e-15],\n",
            "        [1.0000e+00, 3.1126e-20],\n",
            "        [1.0000e+00, 1.8803e-21],\n",
            "        [1.0000e+00, 2.5330e-13],\n",
            "        [1.0000e+00, 5.5391e-12],\n",
            "        [1.0000e+00, 1.7340e-13],\n",
            "        [1.0000e+00, 5.0861e-13],\n",
            "        [1.0000e+00, 3.2678e-16],\n",
            "        [1.0000e+00, 2.5665e-16],\n",
            "        [1.0000e+00, 6.6153e-10],\n",
            "        [1.0000e+00, 2.5313e-13],\n",
            "        [1.0000e+00, 1.0893e-17],\n",
            "        [1.0000e+00, 1.0934e-12],\n",
            "        [1.0000e+00, 8.9995e-11],\n",
            "        [1.0000e+00, 1.9574e-15],\n",
            "        [1.0000e+00, 1.5719e-21],\n",
            "        [1.0000e+00, 5.6933e-20],\n",
            "        [1.0000e+00, 1.3120e-14],\n",
            "        [1.0000e+00, 7.7003e-13],\n",
            "        [1.0000e+00, 4.9387e-16],\n",
            "        [1.0000e+00, 2.2475e-14],\n",
            "        [1.0000e+00, 1.1694e-16],\n",
            "        [1.0000e+00, 2.1994e-15],\n",
            "        [1.0000e+00, 2.3732e-27],\n",
            "        [1.0000e+00, 1.3359e-19],\n",
            "        [1.0000e+00, 3.3018e-10],\n",
            "        [1.0000e+00, 2.6106e-16],\n",
            "        [1.0000e+00, 1.0251e-12],\n",
            "        [1.0000e+00, 8.8785e-24],\n",
            "        [1.0000e+00, 9.8267e-23],\n",
            "        [1.0000e+00, 8.1166e-18],\n",
            "        [1.0000e+00, 1.7351e-21],\n",
            "        [1.0000e+00, 8.5705e-13],\n",
            "        [1.0000e+00, 1.9053e-16],\n",
            "        [1.0000e+00, 1.0448e-12],\n",
            "        [1.0000e+00, 8.0777e-16],\n",
            "        [1.0000e+00, 3.9062e-12],\n",
            "        [1.0000e+00, 2.2008e-24],\n",
            "        [1.0000e+00, 1.9542e-11],\n",
            "        [1.0000e+00, 2.0971e-20],\n",
            "        [1.0000e+00, 1.8279e-17],\n",
            "        [1.0000e+00, 2.4251e-18],\n",
            "        [1.0000e+00, 1.6499e-16],\n",
            "        [1.0000e+00, 1.6068e-12],\n",
            "        [1.0000e+00, 9.0768e-17],\n",
            "        [1.0000e+00, 1.0360e-13],\n",
            "        [1.0000e+00, 3.1021e-13],\n",
            "        [1.0000e+00, 1.5363e-12],\n",
            "        [1.0000e+00, 3.6689e-14],\n",
            "        [1.0000e+00, 6.6043e-24],\n",
            "        [1.0000e+00, 1.6374e-12],\n",
            "        [1.0000e+00, 5.4329e-17],\n",
            "        [1.0000e+00, 5.5698e-15],\n",
            "        [1.0000e+00, 3.5463e-16],\n",
            "        [1.0000e+00, 1.9899e-17],\n",
            "        [1.0000e+00, 9.6418e-20],\n",
            "        [1.0000e+00, 3.0013e-18],\n",
            "        [1.0000e+00, 1.9983e-15],\n",
            "        [1.0000e+00, 4.8197e-17],\n",
            "        [1.0000e+00, 2.7969e-17],\n",
            "        [1.0000e+00, 2.7315e-13],\n",
            "        [1.0000e+00, 1.3612e-21],\n",
            "        [1.0000e+00, 5.0895e-18],\n",
            "        [1.0000e+00, 1.2807e-14],\n",
            "        [1.0000e+00, 2.6106e-16],\n",
            "        [1.0000e+00, 1.5431e-17],\n",
            "        [1.0000e+00, 2.0443e-16],\n",
            "        [1.0000e+00, 1.3096e-15],\n",
            "        [1.0000e+00, 1.2493e-16],\n",
            "        [1.0000e+00, 1.0469e-12],\n",
            "        [1.0000e+00, 1.6897e-12],\n",
            "        [1.0000e+00, 3.6777e-18],\n",
            "        [1.0000e+00, 8.3661e-15],\n",
            "        [1.0000e+00, 1.9467e-14],\n",
            "        [1.0000e+00, 4.6520e-12],\n",
            "        [1.0000e+00, 1.7995e-15],\n",
            "        [1.0000e+00, 1.7650e-14],\n",
            "        [1.0000e+00, 3.1999e-15],\n",
            "        [1.0000e+00, 1.0453e-12],\n",
            "        [1.0000e+00, 2.7665e-17],\n",
            "        [1.0000e+00, 1.1370e-21],\n",
            "        [1.0000e+00, 5.9653e-15],\n",
            "        [1.0000e+00, 1.6936e-20],\n",
            "        [1.0000e+00, 7.3871e-16],\n",
            "        [1.0000e+00, 1.1413e-18],\n",
            "        [1.0000e+00, 1.0939e-11],\n",
            "        [1.0000e+00, 1.2381e-22],\n",
            "        [1.0000e+00, 2.3718e-16],\n",
            "        [1.0000e+00, 3.1987e-15],\n",
            "        [1.0000e+00, 3.5194e-14],\n",
            "        [1.0000e+00, 2.0083e-15],\n",
            "        [1.0000e+00, 2.7516e-18],\n",
            "        [1.0000e+00, 7.0411e-17],\n",
            "        [1.0000e+00, 7.1730e-16],\n",
            "        [1.0000e+00, 7.4551e-13],\n",
            "        [1.0000e+00, 1.6781e-15],\n",
            "        [1.0000e+00, 2.3185e-17],\n",
            "        [1.0000e+00, 1.6068e-12],\n",
            "        [1.0000e+00, 1.6941e-15],\n",
            "        [1.0000e+00, 1.7622e-22],\n",
            "        [1.0000e+00, 3.1231e-18],\n",
            "        [1.0000e+00, 1.4917e-14],\n",
            "        [1.0000e+00, 3.6174e-12],\n",
            "        [1.0000e+00, 3.8451e-18],\n",
            "        [1.0000e+00, 6.3335e-14],\n",
            "        [1.0000e+00, 2.6857e-17],\n",
            "        [1.0000e+00, 1.6550e-16],\n",
            "        [1.0000e+00, 5.2707e-17],\n",
            "        [1.0000e+00, 1.4127e-15],\n",
            "        [1.0000e+00, 1.4639e-12],\n",
            "        [1.0000e+00, 3.1136e-11],\n",
            "        [1.0000e+00, 1.0864e-14],\n",
            "        [1.0000e+00, 3.6657e-19],\n",
            "        [1.0000e+00, 1.3895e-18],\n",
            "        [1.0000e+00, 9.2643e-18],\n",
            "        [1.0000e+00, 2.3999e-15],\n",
            "        [1.0000e+00, 2.4799e-16],\n",
            "        [1.0000e+00, 2.1178e-12],\n",
            "        [1.0000e+00, 4.9500e-14]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the network classifies almost all the patients as the label 0"
      ],
      "metadata": {
        "id": "n5Jvp_wg3hMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(dades_cod_test['UCI'], predictions.argmax(dim=1).tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP8rge0u5CX1",
        "outputId": "498e96f6-9742-4442-b048-11572ea0bd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      1.00      0.97       432\n",
            "         1.0       0.00      0.00      0.00        25\n",
            "\n",
            "    accuracy                           0.95       457\n",
            "   macro avg       0.47      0.50      0.49       457\n",
            "weighted avg       0.89      0.95      0.92       457\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And has bad results, especially predicting the values for Yes. The strategy then will be to try with the upsampled data to see if we can get the network to work a little bit more on the 'Yes' cases:"
      ],
      "metadata": {
        "id": "L2P9H27H6fxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We take just the 70 percent of the data because we will use a part of the test data to do validation for one hiperparameter\n",
        "dades_train_70 = dades.sample(frac=0.7, random_state=25).drop('ID',axis=1)\n",
        "dades_test = dades.drop(dades_train.index).drop('ID',axis=1)\n",
        "\n",
        "dades_train_UCI_No = dades_train_70[dades_train_70['UCI']=='No']\n",
        "dades_train_UCI_Yes = dades_train_70[dades_train_70['UCI']=='Yes']\n",
        "dades_UCI_Yes_upsampled = resample(dades_train_UCI_Yes,replace=True,n_samples=len(dades_train_UCI_No),random_state=123)\n",
        "dades_train_upsampled = pd.concat([dades_train_UCI_No,dades_UCI_Yes_upsampled])"
      ],
      "metadata": {
        "id": "TXTZn2kS5DIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dades_cod_train_upsampled = dades_train_upsampled.drop(['IUGR_missing', 'Size', 'BW'],axis=1).copy()\n",
        "dades_cod_test = dades_test.drop(['IUGR_missing', 'Size', 'BW'],axis=1).copy()\n",
        "\n",
        "for df in [dades_cod_train_upsampled,dades_cod_test]:\n",
        "  df['UCI']=df['UCI'].apply(codUCI)\n",
        "  df['Gender']=df['Gender'].apply(codGender)\n",
        "  df['BW_2500']=df['BW_2500'].apply(codBW)\n",
        "  df['IUGR_calc']=df['IUGR_calc'].apply(codUCI)\n",
        "  for element in df.columns[9:]:\n",
        "    df[element]=df[element].apply(cod)\n",
        "\n",
        "target_train_upsampled = torch.tensor(dades_cod_train_upsampled['UCI'].values)\n",
        "features_train_upsampled = torch.tensor(dades_cod_train_upsampled.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_train_upsampled = TensorDataset(features_train_upsampled,target_train_upsampled)\n",
        "\n",
        "target_test = torch.tensor(dades_cod_test['UCI'].values)\n",
        "features_test = torch.tensor(dades_cod_test.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_test = TensorDataset(features_test, target_test)"
      ],
      "metadata": {
        "id": "lnL2WeFi5D07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a new datset that we will use to train the decison boundary in the future:"
      ],
      "metadata": {
        "id": "sRYxNz3hX__6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We divide into train, validation and test to avoid overfitting:\n",
        "# train_torch,val_torch=random_split(Dades_Tensor_train,[int(0.8*len(Dades_Tensor_train))+1,int(0.2*len(Dades_Tensor_train))],generator=torch.Generator().manual_seed(123))\n",
        "train_torch_upsampled = Dades_Tensor_train_upsampled\n",
        "test_torch, val_torch = random_split(Dades_Tensor_test,[int(0.5*len(Dades_Tensor_test))+1,int(0.5*len(Dades_Tensor_test))],generator=torch.Generator().manual_seed(123))\n",
        "\n",
        "train_torch1_upsampled = DataLoader(train_torch_upsampled,batch_size=50,shuffle=True)\n",
        "val_torch1 = DataLoader(val_torch,batch_size=len(val_torch),shuffle=True)\n",
        "test_torch1 = DataLoader(test_torch,batch_size=len(features_test),shuffle=True)"
      ],
      "metadata": {
        "id": "JmuC5MpH5DxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_upsampling = Network().to(\"cuda\")\n",
        "\n",
        "#training the network:\n",
        "train(model=network_upsampling, \n",
        "      data_loader=train_torch1_upsampled, \n",
        "      loss_function=F.nll_loss, \n",
        "      device=\"cuda\", \n",
        "      optimiser=optim.Adam(network.parameters(),lr=0.0001),\n",
        "      epochs=10)\n",
        "\n",
        "#We store the model in case we want to use it in another script:\n",
        "torch.save(network.state_dict(), \"NN_model_for_COVID-19_patients_upsampled.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k3RFdx35DtY",
        "outputId": "d317d749-833a-4438-ab32-4deee51f4408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Loss: -0.4192551076412201\n",
            "_______________________\n",
            "Epoch 1\n",
            "Loss: -0.40497180819511414\n",
            "_______________________\n",
            "Epoch 2\n",
            "Loss: -0.34472084045410156\n",
            "_______________________\n",
            "Epoch 3\n",
            "Loss: -0.4151182174682617\n",
            "_______________________\n",
            "Epoch 4\n",
            "Loss: -0.39549940824508667\n",
            "_______________________\n",
            "Epoch 5\n",
            "Loss: -0.39517104625701904\n",
            "_______________________\n",
            "Epoch 6\n",
            "Loss: -0.29806965589523315\n",
            "_______________________\n",
            "Epoch 7\n",
            "Loss: -0.40386277437210083\n",
            "_______________________\n",
            "Epoch 8\n",
            "Loss: -0.4387633800506592\n",
            "_______________________\n",
            "Epoch 9\n",
            "Loss: -0.30425772070884705\n",
            "_______________________\n",
            "End of training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here as we added more patients with UCI='Yes' the model performs way better in the train data as we see the loss function decrease significantly. Nevertheless there is the possibility of overfitting."
      ],
      "metadata": {
        "id": "nJ-hE7NBHFbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network_for_test_upsampled = Network()\n",
        "state_dict_upsampled = torch.load(\"NN_model_for_COVID-19_patients_upsampled.pth\")\n",
        "network_for_test_upsampled.load_state_dict(state_dict_upsampled)\n",
        "\n",
        "for input, target in test_torch1:\n",
        "  predictions_upsampled = predict(network_for_test_upsampled, input.float(), target)\n",
        "\n",
        "print(predictions_upsampled.argmax(dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "payquOhY5Dmo",
        "outputId": "307dc311-b8f5-4f4a-81c6-99032a103616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But again the model almost predicts everything to be 0 ('No') so we can't use . \n",
        "We will use the validation dataset to tune the decision bondary and choose one that gives us better results (for the last results we have been using a decision boundary of 0.5).\n",
        "\n",
        "So let's do predictions with the validation dataset:"
      ],
      "metadata": {
        "id": "l4xEz5-5DCEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target in val_torch1:\n",
        "  predictions_upsampled_val = predict(network_for_test_upsampled, input.float(), target)\n",
        "\n",
        "predictions_upsampled_val_df = pd.DataFrame(predictions_upsampled_val.numpy())"
      ],
      "metadata": {
        "id": "f_lGTQCdWWf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\") #We ignore the warnings when we predict the whole datatset to be 'Yes' pr 'No'\n",
        "  accuracies = []\n",
        "\n",
        "  for prob in np.arange(0.99, 1, 0.000005):\n",
        "    predictions_upsampled_val_df['new_predictions'] = (predictions_upsampled_val_df[0] >= prob)\n",
        "    predictions_upsampled_val_df['new_predictions'] = [0. if element_mask else 1. for element_mask in predictions_upsampled_val_df['new_predictions']]\n",
        "    report = classification_report([elem.tolist() for _, elem in val_torch1][0], predictions_upsampled_val_df['new_predictions'], output_dict=True)\n",
        "    accuracies.append({'probability limit': prob, 'precision for No': report['0.0']['precision'], 'precision for Yes': report['1.0']['precision']})"
      ],
      "metadata": {
        "id": "kMmECvqzc8-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_df = pd.DataFrame(accuracies)\n",
        "best_nn = accuracies_df.loc[accuracies_df['precision for No'] >= accuracies_df['precision for No'].max()]\n",
        "print(best_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSy7FrTsrrO0",
        "outputId": "df93492a-1af1-42e4-b2d2-f1abe6a7e335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      probability limit  precision for No  precision for Yes\n",
            "1988            0.99994          0.950226           0.285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model with the best results in the validation dataset has a decision boundary of 0.99994. Let's check the predictions with this boundary in the test set:"
      ],
      "metadata": {
        "id": "GRqdH__ws6tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target in test_torch1:\n",
        "  predictions_upsampled_test = predict(network_for_test_upsampled, input.float(), target)\n",
        "\n",
        "predictions_upsampled_test_df = pd.DataFrame(predictions_upsampled_test.numpy())\n",
        "\n",
        "prob = 0.99994\n",
        "predictions_upsampled_test_df['new_predictions'] = (predictions_upsampled_test_df[0] >= prob)\n",
        "predictions_upsampled_test_df['new_predictions'] = [0. if element_mask else 1. for element_mask in predictions_upsampled_test_df['new_predictions']]\n",
        "report = classification_report([elem.tolist() for _, elem in test_torch1][0], predictions_upsampled_test_df['new_predictions'])\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVbkFRautSFA",
        "outputId": "317c691f-0d67-48d9-e935-9f21439b6e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.96      0.95       217\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.91       229\n",
            "   macro avg       0.47      0.48      0.48       229\n",
            "weighted avg       0.90      0.91      0.90       229\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model coninues to work horrible with unseen data"
      ],
      "metadata": {
        "id": "ImZQIByKv0Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deeper netwok:"
      ],
      "metadata": {
        "id": "0EMFD736PBgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try with a deeper network with the upsampled data:"
      ],
      "metadata": {
        "id": "-ICdhq6HHyja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Deep_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.input_layer=nn.Linear(features_train.size()[1],7) #weights\n",
        "    self.hidden1=nn.Linear(7,7)\n",
        "    self.hidden2=nn.Linear(7,7)\n",
        "    #self.hidden3=nn.Linear(7,10)\n",
        "    #self.hidden4=nn.Linear(10,7)\n",
        "    self.output=nn.Linear(7,2)\n",
        "  \n",
        "  def forward(self, data): #activation functions, we will use the ReLu function\n",
        "    data=F.relu(self.input_layer(data))\n",
        "    data=F.relu(self.hidden1(data))\n",
        "    data=F.relu(self.hidden2(data))\n",
        "    #data=F.relu(self.hidden3(data))\n",
        "    #data=F.relu(self.hidden4(data))\n",
        "    data=self.output(data)\n",
        "    return F.softmax(data, dim=1)"
      ],
      "metadata": {
        "id": "BHSHWjFGISsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deep_network = Deep_network().to(\"cuda\")\n",
        "\n",
        "#training the network:\n",
        "train(model=deep_network, \n",
        "      data_loader=train_torch1_upsampled, \n",
        "      loss_function=F.nll_loss, \n",
        "      device=\"cuda\", \n",
        "      optimiser=optim.Adam(deep_network.parameters(),lr=0.0001),\n",
        "      epochs=10)\n",
        "\n",
        "#We store the model in case we want to use it in another script:\n",
        "torch.save(deep_network.state_dict(), \"deep_NN_model_for_COVID-19_patients.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2R69V0SIb8r",
        "outputId": "d1a17d6e-0f74-4579-bc93-a86d09e0e3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Loss: -0.5025877356529236\n",
            "_______________________\n",
            "Epoch 1\n",
            "Loss: -0.48559218645095825\n",
            "_______________________\n",
            "Epoch 2\n",
            "Loss: -0.490139365196228\n",
            "_______________________\n",
            "Epoch 3\n",
            "Loss: -0.4780896306037903\n",
            "_______________________\n",
            "Epoch 4\n",
            "Loss: -0.4789683222770691\n",
            "_______________________\n",
            "Epoch 5\n",
            "Loss: -0.5023975372314453\n",
            "_______________________\n",
            "Epoch 6\n",
            "Loss: -0.5383976101875305\n",
            "_______________________\n",
            "Epoch 7\n",
            "Loss: -0.5543627738952637\n",
            "_______________________\n",
            "Epoch 8\n",
            "Loss: -0.519188642501831\n",
            "_______________________\n",
            "Epoch 9\n",
            "Loss: -0.5703024864196777\n",
            "_______________________\n",
            "End of training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deep_network_for_test = Deep_network()\n",
        "state_dict_upsampled = torch.load(\"deep_NN_model_for_COVID-19_patients.pth\")\n",
        "deep_network_for_test.load_state_dict(state_dict_upsampled)\n",
        "\n",
        "for input, target in test_torch1:\n",
        "  predictions_upsampled = predict(deep_network_for_test, input.float(), target)\n",
        "\n",
        "print(predictions_upsampled.argmax(dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ9FOkK_I-5f",
        "outputId": "b6a27853-c250-4e9d-cd3d-5f7218157bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
            "        1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
            "        0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
            "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
            "        0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
            "        0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
            "        1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target in val_torch1:\n",
        "  predictions_upsampled_val = predict(deep_network_for_test, input.float(), target)\n",
        "\n",
        "predictions_upsampled_val_df = pd.DataFrame(predictions_upsampled_val.numpy())"
      ],
      "metadata": {
        "id": "dn3EYPHTNd9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\") #We ignore the warnings when we predict the whole datatset to be 'Yes' pr 'No'\n",
        "  accuracies = []\n",
        "\n",
        "  for prob in np.arange(0, 1, 0.025):\n",
        "    predictions_upsampled_val_df['new_predictions'] = (predictions_upsampled_val_df[0] >= prob)\n",
        "    predictions_upsampled_val_df['new_predictions'] = [0. if element_mask else 1. for element_mask in predictions_upsampled_val_df['new_predictions']]\n",
        "    report = classification_report([elem.tolist() for _, elem in val_torch1][0], predictions_upsampled_val_df['new_predictions'], output_dict=True)\n",
        "    accuracies.append({'probability limit': prob, 'precision for No': report['0.0']['precision'], 'precision for Yes': report['1.0']['precision']})"
      ],
      "metadata": {
        "id": "IBP1Wj5RI-wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We let the accuracy for the 'No' be a little worst so we can check more models"
      ],
      "metadata": {
        "id": "Z6rwIgOiOaFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_df = pd.DataFrame(accuracies)\n",
        "best_nn = accuracies_df.loc[accuracies_df['precision for No'] >= accuracies_df['precision for No'].max() - 0.04]\n",
        "print(best_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbd9upXXKOHK",
        "outputId": "acab5213-80be-4fad-be90-8c46f799d6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    probability limit  precision for No  precision for Yes\n",
            "0               0.000          0.942982           0.000000\n",
            "1               0.025          0.942731           0.000000\n",
            "2               0.050          0.942478           0.000000\n",
            "3               0.075          0.946429           0.250000\n",
            "4               0.100          0.941176           0.000000\n",
            "5               0.125          0.940092           0.000000\n",
            "6               0.150          0.949074           0.166667\n",
            "7               0.175          0.942857           0.055556\n",
            "8               0.200          0.946602           0.090909\n",
            "9               0.225          0.939698           0.034483\n",
            "10              0.250          0.943005           0.057143\n",
            "11              0.275          0.940217           0.045455\n",
            "12              0.300          0.938547           0.040816\n",
            "13              0.325          0.934524           0.033333\n",
            "14              0.350          0.950000           0.073529\n",
            "15              0.375          0.935065           0.040541\n",
            "16              0.400          0.947020           0.064935\n",
            "17              0.425          0.946309           0.063291\n",
            "18              0.450          0.945205           0.060976\n",
            "19              0.475          0.947368           0.063158\n",
            "20              0.500          0.953125           0.070000\n",
            "21              0.525          0.941667           0.055556\n",
            "22              0.550          0.956522           0.070796\n",
            "23              0.575          0.916667           0.033333\n",
            "24              0.600          0.939394           0.054264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will choose prob = 0.075"
      ],
      "metadata": {
        "id": "VExilDLoOF8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob = 0.075\n",
        "\n",
        "for input, target in test_torch1:\n",
        "  predictions_upsampled_test = predict(deep_network_for_test, input.float(), target)\n",
        "\n",
        "predictions_upsampled_test_df = pd.DataFrame(predictions_upsampled_test.numpy())\n",
        "\n",
        "predictions_upsampled_test_df['new_predictions'] = (predictions_upsampled_test_df[0] >= prob)\n",
        "predictions_upsampled_test_df['new_predictions'] = [0. if element_mask else 1. for element_mask in predictions_upsampled_test_df['new_predictions']]\n",
        "report = classification_report([elem.tolist() for _, elem in test_torch1][0], predictions_upsampled_test_df['new_predictions'])\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiVuXLvBOY0r",
        "outputId": "8ccbd1fc-2cd5-434b-9689-ff4e1bf0f632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.99      0.97       217\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.93       229\n",
            "   macro avg       0.47      0.49      0.48       229\n",
            "weighted avg       0.90      0.93      0.92       229\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We fail again to get the network to predict focus too on the patiens with UCI = 1"
      ],
      "metadata": {
        "id": "SOmw4lM7Qamr"
      }
    }
  ]
}